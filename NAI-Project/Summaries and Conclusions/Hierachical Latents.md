
Hierarchy and interdependence are nonetheless somewhat implicitely covered in most succesfull deep learning models, as has been shown often for e.g. #CNN s [see NAI Lecture 12, Vicente 2022]. Something similar applies to [[Transformer]]s, which model interdependence of latent tokens' meanings through attention. The multiple attention layers have been shown to capture different kinds of abstraction []. Together with the fact that eg. programming languages demonstrate how finite, a-priori unnested, sequences of tokens can express arbitrarily complex, nested and self-referential structures, [[Transformer]]s can be seen as fuzzy interpreters 

# Hierarchical Latents

Referred in <a href="./Project-H7YNYZS4.md" rel="noopener noreferrer nofollow" zhref="zotero://note/u/H7YNYZS4/?ignore=1&#x26;line=18" ztype="znotelink" class="internal-link">Project/Open Questions</a>

(generalize sequences to trees)

current pathways: Bayesian: Nested Hierarchical Dirichlet Processes <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2Flocal%2Fi56aMdXP%2Fitems%2FIR6G9UPG%22%5D%7D%5D%2C%22properties%22%3A%7B%7D%7D" ztype="zcitation">(<span class="citation-item"><a href="zotero://select/library/items/IR6G9UPG">Paisley et al., 2015</a></span>)</span>
